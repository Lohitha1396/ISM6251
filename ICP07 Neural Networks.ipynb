{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0tyra0NWJvI"
   },
   "source": [
    "## MNIST machine learning exercise\n",
    "\n",
    "In this exercise we will compare the performance of three different modeling approaches at predicting handwritten numbers. \n",
    "\n",
    "We use the MNIST data set;\n",
    "\n",
    "![mnist data](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmAFVhDJXFBb"
   },
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "48VnFR9cXFP0"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "import pandas as pd\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YI7yVb-VW2zi"
   },
   "source": [
    "## Load data and explore/get to know the data structure\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MNIST digits dataset. It's originally from UCI machine learning library, but included in SKLearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "M8CjaVlYW2Jx",
    "outputId": "e90a4dd3-3781-477f-b02f-97ac3e75be91"
   },
   "outputs": [],
   "source": [
    "mnist = datasets.load_digits() # sklearn includes this data set .. https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the dataset is stored in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "5pPXrazAfUoL",
    "outputId": "593b0df0-7b98-4c9b-e01d-36930d653723"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note thjat there are 1797 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "rTQ7qNp4ffaW",
    "outputId": "3d267533-ac01-4747-abee-369aae5d3d79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1797\n"
     ]
    }
   ],
   "source": [
    "print(len(mnist.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images are 8x8 grid of values epresenting the gray level for each pixel (16 levels of grey -- from 0 (black) to 15 (white)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "B0ZaSvLlfva0",
    "outputId": "7735e16a-6f2e-41cd-e4e3-55c1dbd5a89d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
       "       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
       "       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
       "       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
       "       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
       "       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
       "       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyze this, we simple turn this into a one dimensional array (so we will x1, x2, ... x63, x64). This has already been done for us, and is stored in the data key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "sjDP19CWfT6S",
    "outputId": "f3643de4-6fc9-4810-d5d5-21fb633970fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "Pi5Fvsd_dry5",
    "outputId": "d61e56b6-99c4-486c-b4fa-523f3cb7f1d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(mnist.target[0])\n",
    "print(mnist.target[1])\n",
    "print(mnist.target[2])\n",
    "print(mnist.target[3])\n",
    "print(mnist.target[4])\n",
    "print(mnist.target[5])\n",
    "print(mnist.target[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use matplotlib to display a sample of these images from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qW162_28WC60",
    "outputId": "c7bf771d-ebd1-4a42-e9e4-719d243b814a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAKz0lEQVR4nO3d34tc9RnH8c+nq9L6M9DaELIhUZCAFLqREJCAkNiWWMVU6EUCCgmFeKMktCDaK/MPyPaiCEt0I5gqbdRExGoFDVZorUnctCYbSxq3ZBtt1BL8UWiIPr3YCUS76Z45c37t4/sFwd3ZYb/PEN85Z2dnztcRIQB5fK3tAQBUi6iBZIgaSIaogWSIGkjmojq+qe2UT6kvWrSo0fUWLlzY2FpDQ0ONrdWkqampRtf78MMPG1srIjzb7bVEndXdd9/d6Hrbtm1rbK2rrrqqsbWatHnz5kbX27lzZ6PrzYbTbyAZogaSIWogGaIGkiFqIBmiBpIhaiAZogaSIWogmUJR215n+23bx2zfX/dQAMqbM2rbQ5J+KekWSddL2mj7+roHA1BOkSP1KknHIuJ4RJyR9KSk9fWOBaCsIlEvlnTivM+ne7d9ge0ttvfb3l/VcAD6V+RdWrO9vet/3loZEWOSxqS8b70E5oMiR+ppSUvO+3xY0sl6xgEwqCJRvyHpOtvX2L5E0gZJz9Y7FoCy5jz9joiztu+R9KKkIUmPRsTh2icDUEqhK59ExPOSnq95FgAV4BVlQDJEDSRD1EAyRA0kQ9RAMkQNJEPUQDKuY9P5Jl/7vWzZsqaW0jvvvNPYWpK0d+/extYaHx9vbK0mH1dmF9p2hyM1kAxRA8kQNZAMUQPJEDWQDFEDyRA1kAxRA8kQNZAMUQPJFNmh41Hbp2y/1cRAAAZT5Ei9U9K6mucAUJE5o46IVyX9q4FZAFSg0NVEi7C9RdKWqr4fgHIqi5ptd4Bu4NlvIBmiBpIp8iutJyT9QdJy29O2f1L/WADKKrKX1sYmBgFQDU6/gWSIGkiGqIFkiBpIhqiBZIgaSIaogWQqe+13WxYsWND2CLVhKxyUwZEaSIaogWSIGkiGqIFkiBpIhqiBZIgaSIaogWSIGkiGqIFkilyjbIntV2xP2j5se2sTgwEop8hrv89K+llEHLR9haQDtl+KiCM1zwaghCLb7rwbEQd7H38saVLS4roHA1BOX+/Ssr1M0gpJr8/yNbbdATqgcNS2L5f0lKRtEfHRl7/OtjtANxR69tv2xZoJeldEPF3vSAAGUeTZb0t6RNJkRDxU/0gABlHkSL1a0l2S1tqe6P35Yc1zASipyLY7r0lyA7MAqACvKAOSIWogGaIGkiFqIBmiBpIhaiAZogaSIWogmXm/l9bSpUvbHqE2e/bsaWytQ4cONbbWyMhIY2t9FXGkBpIhaiAZogaSIWogGaIGkiFqIBmiBpIhaiAZogaSKXLhwa/b/pPtQ71td7Y3MRiAcoq8TPQ/ktZGxCe9SwW/Zvu3EfHHmmcDUEKRCw+GpE96n17c+8PF+oGOKnox/yHbE5JOSXopImbddsf2ftv7K54RQB8KRR0Rn0XEiKRhSatsf2eW+4xFxMqIWFnxjAD60Nez3xFxWtI+SevqGAbA4Io8+3217QW9j78h6XuSjtY8F4CSijz7vUjSY7aHNPOPwK8j4rl6xwJQVpFnv/+smT2pAcwDvKIMSIaogWSIGkiGqIFkiBpIhqiBZIgaSIaogWTm/bY7d9xxR2NrNbk1jSSNjo6mXGv9+vWNrbV3797G1uoKjtRAMkQNJEPUQDJEDSRD1EAyRA0kQ9RAMkQNJEPUQDJEDSRTOOreBf3ftM1FB4EO6+dIvVXSZF2DAKhG0W13hiXdKmlHveMAGFTRI/WopPskfX6hO7CXFtANRXbouE3SqYg48P/ux15aQDcUOVKvlnS77SlJT0paa/vxWqcCUNqcUUfEAxExHBHLJG2Q9HJE3Fn7ZABK4ffUQDJ9Xc4oIvZpZitbAB3FkRpIhqiBZIgaSIaogWSIGkiGqIFkiBpIxhFR/Te1q/+mFzAyMtLUUpqammpsLUk6ffp0Y2vt2bOnsbUmJiYaW+vBBx9sbK2mRYRnu50jNZAMUQPJEDWQDFEDyRA1kAxRA8kQNZAMUQPJEDWQDFEDyRS6nFHvSqIfS/pM0lkuAwx0Vz/XKFsTER/UNgmASnD6DSRTNOqQ9DvbB2xvme0ObLsDdEPR0+/VEXHS9rclvWT7aES8ev4dImJM0pjU7FsvAXxRoSN1RJzs/feUpGckrapzKADlFdkg7zLbV5z7WNIPJL1V92AAyily+r1Q0jO2z93/VxHxQq1TAShtzqgj4rik7zYwC4AK8CstIBmiBpIhaiAZogaSIWogGaIGkiFqIJl5v+1OZps2bWpsrfHx8cbWWrNmTWNr7du3r7G1msa2O8BXBFEDyRA1kAxRA8kQNZAMUQPJEDWQDFEDyRA1kAxRA8kUitr2Atu7bR+1PWn7xroHA1BO0et+/0LSCxHxY9uXSLq0xpkADGDOqG1fKekmSZskKSLOSDpT71gAyipy+n2tpPcljdt+0/aO3vW/v4Btd4BuKBL1RZJukPRwRKyQ9Kmk+798p4gYi4iVbHMLtKtI1NOSpiPi9d7nuzUTOYAOmjPqiHhP0gnby3s33SzpSK1TASit6LPf90ra1Xvm+7ikzfWNBGAQhaKOiAlJ/KwMzAO8ogxIhqiBZIgaSIaogWSIGkiGqIFkiBpIhqiBZIq+ogySRkdHG11v69atja21ffv2xtbKvL9VF3CkBpIhaiAZogaSIWogGaIGkiFqIBmiBpIhaiAZogaSmTNq28ttT5z35yPb2xqYDUAJc75MNCLeljQiSbaHJP1D0jP1jgWgrH5Pv2+W9LeI+HsdwwAYXL9v6Ngg6YnZvmB7i6QtA08EYCCFj9S9a37fLuk3s32dbXeAbujn9PsWSQcj4p91DQNgcP1EvVEXOPUG0B2ForZ9qaTvS3q63nEADKrotjv/lvTNmmcBUAFeUQYkQ9RAMkQNJEPUQDJEDSRD1EAyRA0kQ9RAMo6I6r+p/b6kft+e+S1JH1Q+TDdkfWw8rvYsjYirZ/tCLVGXYXt/1nd4ZX1sPK5u4vQbSIaogWS6FPVY2wPUKOtj43F1UGd+pgZQjS4dqQFUgKiBZDoRte11tt+2fcz2/W3PUwXbS2y/YnvS9mHbW9ueqUq2h2y/afu5tmepku0FtnfbPtr7u7ux7Zn61frP1L0NAv6qmcslTUt6Q9LGiDjS6mADsr1I0qKIOGj7CkkHJP1ovj+uc2z/VNJKSVdGxG1tz1MV249J+n1E7OhdQffSiDjd8lh96cKRepWkYxFxPCLOSHpS0vqWZxpYRLwbEQd7H38saVLS4nanqobtYUm3StrR9ixVsn2lpJskPSJJEXFmvgUtdSPqxZJOnPf5tJL8z3+O7WWSVkh6veVRqjIq6T5Jn7c8R9WulfS+pPHejxY7bF/W9lD96kLUnuW2NL9ns325pKckbYuIj9qeZ1C2b5N0KiIOtD1LDS6SdIOkhyNihaRPJc2753i6EPW0pCXnfT4s6WRLs1TK9sWaCXpXRGS5vPJqSbfbntLMj0prbT/e7kiVmZY0HRHnzqh2aybyeaULUb8h6Trb1/SemNgg6dmWZxqYbWvmZ7PJiHio7XmqEhEPRMRwRCzTzN/VyxFxZ8tjVSIi3pN0wvby3k03S5p3T2z2u0Fe5SLirO17JL0oaUjSoxFxuOWxqrBa0l2S/mJ7onfbzyPi+fZGQgH3StrVO8Acl7S55Xn61vqvtABUqwun3wAqRNRAMkQNJEPUQDJEDSRD1EAyRA0k818WzZMOh6VzFAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in np.random.choice(range(0,len(mnist.images)), 4): # choose 4 at random\n",
    "  plt.imshow(mnist.images[i], cmap='gray')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(mnist.data, mnist.target, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5WfGTWb3hYd-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 578 ms\n",
      "Wall time: 6.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ann = MLPClassifier(hidden_layer_sizes=(60,50,40), solver='adam', max_iter=200)\n",
    "_ = ann.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = ann.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       1.00      1.00      1.00        35\n",
      "           2       0.97      1.00      0.99        36\n",
      "           3       0.95      0.98      0.96        41\n",
      "           4       0.95      0.97      0.96        38\n",
      "           5       0.97      0.97      0.97        30\n",
      "           6       1.00      1.00      1.00        37\n",
      "           7       0.97      0.95      0.96        37\n",
      "           8       0.96      0.93      0.95        29\n",
      "           9       0.94      0.97      0.96        34\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "{'solver': 'adam', 'max_iter': 5000, 'learning_rate_init': 0.001, 'learning_rate': 'constant', 'hidden_layer_sizes': (70,), 'alpha': 0.5, 'activation': 'tanh'}\n",
      "CPU times: total: 4.11 s\n",
      "Wall time: 6min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (50,), (70,),(50,30), (40,20), (60,40, 20), (70,50,40)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0, .2, .5, .7, 1],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1, 0.2, 0.5],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = RandomizedSearchCV(estimator = ann, param_distributions=param_grid, cv=kfolds, n_iter=100,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.97      1.00      0.99        35\n",
      "           2       1.00      1.00      1.00        36\n",
      "           3       0.98      1.00      0.99        41\n",
      "           4       1.00      1.00      1.00        38\n",
      "           5       0.93      0.93      0.93        30\n",
      "           6       1.00      1.00      1.00        37\n",
      "           7       1.00      0.97      0.99        37\n",
      "           8       1.00      0.93      0.96        29\n",
      "           9       0.94      0.97      0.96        34\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 15.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "{'activation': 'relu', 'alpha': 0.7, 'hidden_layer_sizes': (70,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'max_iter': 5000, 'solver': 'adam'}\n",
      "CPU times: total: 2.56 s\n",
      "Wall time: 3min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (30,), (50,), (70,), (90,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [.5, .7, 1],\n",
    "    'learning_rate': ['adaptive', 'invscaling'],\n",
    "    'learning_rate_init': [0.005, 0.01, 0.15],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = GridSearchCV(estimator = ann, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.97      1.00      0.99        35\n",
      "           2       1.00      1.00      1.00        36\n",
      "           3       0.98      0.98      0.98        41\n",
      "           4       0.95      1.00      0.97        38\n",
      "           5       0.93      0.93      0.93        30\n",
      "           6       1.00      1.00      1.00        37\n",
      "           7       1.00      0.92      0.96        37\n",
      "           8       0.94      1.00      0.97        29\n",
      "           9       1.00      0.97      0.99        34\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier = classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.97      1.00      0.99        35\n",
      "           2       1.00      1.00      1.00        36\n",
      "           3       0.98      0.98      0.98        41\n",
      "           4       0.95      1.00      0.97        38\n",
      "           5       0.93      0.93      0.93        30\n",
      "           6       1.00      1.00      1.00        37\n",
      "           7       1.00      0.92      0.96        37\n",
      "           8       0.94      1.00      0.97        29\n",
      "           9       1.00      0.97      0.99        34\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree model with RandomsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "The best accuracy score is 0.8399704800619435\n",
      "... with parameters: {'min_samples_split': 7, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0051, 'max_leaf_nodes': 112, 'max_depth': 20, 'criterion': 'entropy'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dkrre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "40 fits failed out of a total of 2500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dkrre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dkrre\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\dkrre\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\dkrre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.75432878 0.1892712  0.80863821 0.75431185 0.72512098 0.77593157\n",
      " 0.76268631 0.76615854 0.75228659 0.78147745 0.72930701 0.80098238\n",
      " 0.73902923 0.70705575 0.76131678 0.7863555  0.72930701 0.63118225\n",
      " 0.78774681 0.80096545 0.76898713 0.72023326 0.77245693 0.74321283\n",
      " 0.8135211  0.7251234  0.72093738 0.78148713 0.75854626 0.78705962\n",
      " 0.78773229 0.75993757 0.76965979 0.77868515 0.71189992 0.73413908\n",
      " 0.71816202 0.57274245 0.72442654 0.79540505 0.72650987 0.78217915\n",
      " 0.72789876 0.80306814 0.78845093 0.71885405 0.82951994 0.19485579\n",
      " 0.71329849 0.80585075 0.76480836 0.80444251 0.72650987 0.77662602\n",
      " 0.77872145 0.78428184 0.72860288 0.72860288 0.71745548 0.57274245\n",
      " 0.72512098 0.41963318 0.74739402 0.80515389 0.7473674  0.7536658\n",
      " 0.64721254 0.70356901 0.77106078 0.72581301 0.63745403 0.71885405\n",
      " 0.70356901 0.80724932 0.78498597 0.55393922 0.62979094 0.83300184\n",
      " 0.72442654 0.57622435 0.71747726 0.71745548        nan 0.78774439\n",
      " 0.72094948 0.76686508 0.72931185 0.75432878 0.75083479 0.71814992\n",
      " 0.74671409 0.78566831 0.7898495  0.70356901 0.75226965 0.72930701\n",
      " 0.79820703 0.76895809 0.71190476 0.34239015 0.76203058 0.73693622\n",
      " 0.80238095 0.76689654 0.66530923 0.74876355 0.70566444 0.64721254\n",
      " 0.71814992 0.83997048 0.76689654 0.72163424 0.53444638 0.74945074\n",
      " 0.7633856  0.73762824 0.8093375  0.72512098 0.7494459  0.66113047\n",
      " 0.80862853 0.79260792 0.79611401 0.78217431 0.7153794  0.77175765\n",
      " 0.7494459  0.72931185 0.70705575 0.73626113 0.78637485 0.6722561\n",
      " 0.75919232 0.74041812 0.71815476 0.79054394 0.79332172 0.78428668\n",
      " 0.75710172 0.76619483 0.70426345 0.76968157 0.74041812 0.78427458\n",
      " 0.76268631 0.78704994 0.61730062 0.72648326 0.78635308 0.77037602\n",
      " 0.44748113 0.71815476 0.72442654 0.70705575 0.71885405 0.70356901\n",
      " 0.77033488 0.80306572        nan 0.70774535 0.74041812 0.75432636\n",
      " 0.71610046 0.19485579 0.75297377 0.77245451 0.76893631 0.7153794\n",
      " 0.74667296        nan 0.71745548 0.71676103 0.74736982 0.72930701\n",
      " 0.7244459  0.73624903 0.71676103 0.78217431 0.77663086 0.75432636\n",
      " 0.74253533 0.72442654 0.75855352 0.78845335 0.72373693 0.83299458\n",
      " 0.76689654 0.77245451 0.77872145 0.77661634 0.65973674 0.76968157\n",
      " 0.77591221 0.77590738 0.78843157 0.31384533 0.79124081 0.7243975\n",
      "        nan 0.7153794  0.75154133 0.79263695 0.78566105 0.72648326\n",
      " 0.7153794  0.75226965 0.72650503 0.75502323 0.61241289        nan\n",
      " 0.83927362 0.70705575 0.79401858 0.7251234  0.71676103 0.78148471\n",
      " 0.79400165 0.48990031 0.81350416 0.70705575 0.78148955 0.75432636\n",
      " 0.70426345 0.75640002 0.70218012 0.7251234  0.68132017 0.63187669\n",
      " 0.71745548 0.8107288  0.8107288  0.83510211 0.72931185 0.70566444\n",
      " 0.76408004 0.75994241 0.70705575 0.45790989 0.76824913 0.52959979\n",
      " 0.72307636 0.70287698 0.72093738 0.79957172 0.71329849 0.34239015\n",
      " 0.19485579 0.77176007 0.78428184 0.77033488 0.77383372 0.77037602\n",
      " 0.77663328 0.74321283 0.72860288 0.71885405 0.784277   0.76825155\n",
      " 0.76059814 0.75014034 0.78637485 0.77871661 0.72442654 0.73624903\n",
      " 0.72931185 0.78637485 0.72373693 0.76689654 0.72932395 0.75854868\n",
      " 0.73624903 0.81560201 0.1892712  0.61865079 0.72094948 0.71468738\n",
      " 0.74876355 0.73624661 0.70566444 0.77593157 0.75363192 0.73763792\n",
      " 0.72442654 0.72442654 0.76758856 0.72860288 0.73623935 0.7494459\n",
      " 0.34239015 0.75223577 0.7633856  0.79820703 0.73769357 0.19485579\n",
      " 0.74321283 0.75226965 0.79400165 0.81976626 0.75432636 0.79679394\n",
      " 0.65626936 0.7251234  0.77732772 0.80376742 0.7710753  0.72373693\n",
      " 0.75502323 0.7682951  0.71329849 0.80514663 0.76968157 0.79193525\n",
      " 0.77033488 0.76202091 0.78010792 0.72930701 0.71885405 0.77176732\n",
      " 0.44886276 0.81839189 0.77869483 0.77872145 0.78913569 0.71468738\n",
      " 0.78983014 0.76131678 0.80096545 0.74875871 0.79820703 0.71676103\n",
      " 0.75432636 0.71816202 0.72023326 0.71815476 0.6492983  0.71399293\n",
      " 0.75154133 0.73485288 0.70426345 0.71676103 0.75432636 0.65418118\n",
      " 0.73624661 0.53029423 0.80166231        nan 0.77106804 0.65133566\n",
      " 0.77176732 0.69106175 0.54141018 0.83090157 0.69314508 0.7968133\n",
      " 0.77869483 0.78635066 0.75506194 0.72650987 0.70705575 0.82674216\n",
      " 0.74736982 0.66392276 0.72789876 0.78425765 0.77382888 0.73485288\n",
      " 0.81280972 0.71746032 0.65133566 0.71399293 0.77942799 0.72373693\n",
      " 0.1892712  0.79820703 0.72023326 0.82881823 0.74321283 0.61730062\n",
      " 0.72442654 0.77034698 0.73624903 0.75993757 0.82671796 0.79263211\n",
      " 0.74321283 0.72442654        nan 0.78146777 0.31384533 0.82393777\n",
      "        nan 0.75993757 0.71885405 0.7320872  0.70287698 0.78637727\n",
      " 0.55394164 0.75432636 0.75645325 0.72442654 0.73838802 0.45860676\n",
      " 0.81003436 0.70287698 0.75363192 0.70566444 0.71814992 0.71329849\n",
      " 0.71814992 0.7494459  0.79957172 0.78357772 0.72930701 0.75091221\n",
      " 0.72648326 0.77034214 0.73485288 0.74875145 0.75014034 0.78496661\n",
      " 0.79054152 0.68410521 0.78356562 0.78843157 0.74811266 0.76615854\n",
      " 0.76202091 0.78637485 0.79748113 0.34239015 0.71676103 0.74601723\n",
      " 0.76968157 0.76964044 0.7633856  0.7641115  0.71816202 0.72442654\n",
      " 0.31384533 0.70426345 0.71676103 0.53238482 0.7473674  0.69593254\n",
      " 0.70566444 0.31384533 0.77663569 0.76129501 0.75432636 0.81071187\n",
      " 0.70774535 0.72305943 0.73557878 0.76894599 0.80237853 0.81908633\n",
      " 0.72930701 0.75500629 0.70356901 0.75226965 0.46557298 0.72931185\n",
      " 0.70426345 0.72442654 0.77310782 0.77732772 0.77034214 0.72373693\n",
      " 0.78567073 0.73624661 0.80794619 0.78707172 0.75083479 0.71885405\n",
      " 0.74736982 0.6722561  0.76480836 0.70287698 0.79194251 0.34239015\n",
      " 0.69383953 0.72648326 0.78357772 0.70705575 0.7835511  0.70426345\n",
      " 0.71676103 0.82812863 0.78427458 0.78915505 0.74736982 0.71745548\n",
      " 0.7536174  0.72931185 0.75432636 0.54001887 0.73624903 0.75297377\n",
      " 0.73762824 0.7494459 ]\n",
      "  warnings.warn(\n",
      "C:\\Users\\dkrre\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [0.80428108 0.19728702 0.89370341 0.79958194 0.764267   0.83681568\n",
      " 0.81176115 0.81176115 0.80515306 0.82654861 0.79488902 0.87212745\n",
      " 0.77244455 0.76235547 0.81663465 0.84081341 0.79488902 0.65604753\n",
      " 0.84237938 0.86725773 0.84446997 0.7546983  0.84499338 0.80376252\n",
      " 0.90605426 0.75904764 0.77940788 0.84220577 0.82150588 0.84986325\n",
      " 0.84725122 0.8133291  0.82654588 0.83698596 0.74912854 0.76339698\n",
      " 0.78253831 0.59481515 0.7585259  0.86378204 0.75835184 0.8380311\n",
      " 0.76444106 0.87700291 0.84951603 0.77627578 0.91910289 0.19485072\n",
      " 0.77279479 0.87282688 0.83437923 0.87108593 0.75835184 0.83681568\n",
      " 0.84725334 0.84603549 0.78949665 0.78949665 0.75522049 0.59481515\n",
      " 0.764267   0.43510788 0.80741605 0.87282688 0.78322958 0.8093291\n",
      " 0.674665   0.76357332 0.8382085  0.75800401 0.66927006 0.77627578\n",
      " 0.76357332 0.88796231 0.84360071 0.58402679 0.64769955 0.93127937\n",
      " 0.76235229 0.60611708 0.76340001 0.75522049        nan 0.8373353\n",
      " 0.78601673 0.81106429 0.79123487 0.80428108 0.79436213 0.75556862\n",
      " 0.81402233 0.84916396 0.85577871 0.76357332 0.80915458 0.79488902\n",
      " 0.86151845 0.82184917 0.77505733 0.35716563 0.81298187 0.7693126\n",
      " 0.86865161 0.81733061 0.70215628 0.78375237 0.76131154 0.674665\n",
      " 0.75556862 0.93841435 0.81733061 0.75643819 0.56645734 0.78305687\n",
      " 0.81350089 0.76861664 0.87752526 0.764267   0.79697188 0.70093753\n",
      " 0.8801335  0.85351481 0.86847951 0.83211564 0.77140258 0.83873024\n",
      " 0.79697188 0.79123487 0.76235547 0.79784705 0.8582141  0.70563757\n",
      " 0.80219351 0.80184917 0.77679797 0.8606454  0.85699671 0.85960601\n",
      " 0.80027896 0.82742135 0.76548802 0.82550664 0.80184917 0.84638468\n",
      " 0.81176115 0.83594309 0.64456624 0.75400235 0.83994445 0.82550664\n",
      " 0.4685113  0.77679797 0.7585259  0.76235547 0.77627578 0.76357332\n",
      " 0.81628425 0.87282688        nan 0.7595715  0.80184917 0.78897007\n",
      " 0.7734856  0.19485072 0.81402702 0.83194521 0.81854709 0.77140258\n",
      " 0.77975192        nan 0.75522049 0.7546983  0.78218716 0.79488902\n",
      " 0.77383721 0.76792144 0.7546983  0.83211564 0.84046876 0.78897007\n",
      " 0.80463057 0.7585259  0.82411473 0.85229894 0.78793022 0.92745419\n",
      " 0.81733061 0.83194521 0.84725334 0.8362888  0.70076361 0.82550664\n",
      " 0.82376479 0.83385522 0.84707822 0.31524002 0.85577871 0.75104386\n",
      "        nan 0.77140258 0.78427426 0.86621698 0.84899202 0.75400235\n",
      " 0.77140258 0.80915458 0.75695478 0.80428108 0.63291058        nan\n",
      " 0.9493739  0.76235547 0.86117198 0.75904764 0.7546983  0.84412351\n",
      " 0.85873493 0.50399909 0.87891338 0.76235547 0.84168419 0.78897007\n",
      " 0.76548802 0.80167072 0.76426957 0.75904764 0.71624869 0.65726522\n",
      " 0.75522049 0.88117728 0.88117728 0.93876218 0.79123487 0.76131154\n",
      " 0.81489265 0.81785326 0.76235547 0.47790502 0.81176115 0.54279638\n",
      " 0.78531547 0.75870163 0.77940788 0.8590826  0.77279479 0.35716563\n",
      " 0.19485072 0.8357719  0.85891051 0.81628425 0.83994733 0.82550664\n",
      " 0.839077   0.80376252 0.78949665 0.77627578 0.85403852 0.81889507\n",
      " 0.81384917 0.79279631 0.84360071 0.84446997 0.76235229 0.76792144\n",
      " 0.79123487 0.84360071 0.78793022 0.81733061 0.76983479 0.82063662\n",
      " 0.76792144 0.90187868 0.19728702 0.64352443 0.78601673 0.77401294\n",
      " 0.78375237 0.76983479 0.76131154 0.83681568 0.80758694 0.80324078\n",
      " 0.76235229 0.76235229 0.82863874 0.78949665 0.76896477 0.79697188\n",
      " 0.35716563 0.78775268 0.81350089 0.86151845 0.79453907 0.19485072\n",
      " 0.80376252 0.80915458 0.85873493 0.89074507 0.78897007 0.86064934\n",
      " 0.69450093 0.75904764 0.84273024 0.87665539 0.83420517 0.78793022\n",
      " 0.80428108 0.82533303 0.77279479 0.87143285 0.82550664 0.8543862\n",
      " 0.81576252 0.8209843  0.83855572 0.79488902 0.77627578 0.84377568\n",
      " 0.46572748 0.91336133 0.82567919 0.84725334 0.85316547 0.77401294\n",
      " 0.8514268  0.81663465 0.86725773 0.80619503 0.86151845 0.7546983\n",
      " 0.78897007 0.78253831 0.7546983  0.77679797 0.6857971  0.7722726\n",
      " 0.78427426 0.76983479 0.76548802 0.7546983  0.78897007 0.69276134\n",
      " 0.76983479 0.54314451 0.86952253        nan 0.83542332 0.66927461\n",
      " 0.83507519 0.72511689 0.55688637 0.92240845 0.72772695 0.86777841\n",
      " 0.83681175 0.83455148 0.81072101 0.75835184 0.76235547 0.91996927\n",
      " 0.78218716 0.70111235 0.76444106 0.83663919 0.82689431 0.76983479\n",
      " 0.88743997 0.77801582 0.66927461 0.7722726  0.84934166 0.78793022\n",
      " 0.19728702 0.86151845 0.7546983  0.92153843 0.80376252 0.64456624\n",
      " 0.7585259  0.82202369 0.76792144 0.8133291  0.91022939 0.85891005\n",
      " 0.80376252 0.7585259         nan 0.83907383 0.31524002 0.90988186\n",
      "        nan 0.8133291  0.77627578 0.77087221 0.75870163 0.8653468\n",
      " 0.5854187  0.78897007 0.81820229 0.7585259  0.79279918 0.47546994\n",
      " 0.88117728 0.75870163 0.80428108 0.76131154 0.75556862 0.77279479\n",
      " 0.75556862 0.79697188 0.86204049 0.8475995  0.79488902 0.808979\n",
      " 0.75400235 0.82098203 0.76983479 0.79175192 0.79279631 0.8439443\n",
      " 0.85142907 0.7202499  0.84603277 0.84707822 0.81089386 0.81176115\n",
      " 0.8209843  0.84360071 0.86151845 0.35716563 0.7546983  0.81297885\n",
      " 0.82550664 0.812979   0.81489265 0.82916124 0.78253831 0.76235229\n",
      " 0.31524002 0.76548802 0.7546983  0.54401408 0.78340364 0.72911825\n",
      " 0.76131154 0.31524002 0.84307806 0.80480039 0.78897007 0.88135044\n",
      " 0.7595715  0.78862164 0.78913974 0.81785083 0.86865161 0.89787763\n",
      " 0.79488902 0.80167072 0.76357332 0.80915458 0.48869081 0.79123487\n",
      " 0.76548802 0.7585259  0.81872055 0.839077   0.82098203 0.78793022\n",
      " 0.84829803 0.76983479 0.87178265 0.86256329 0.79436213 0.77627578\n",
      " 0.78218716 0.70563757 0.82202793 0.75870163 0.86465115 0.35716563\n",
      " 0.72633443 0.75400235 0.84463844 0.76235547 0.83855254 0.76548802\n",
      " 0.7546983  0.91492746 0.84481492 0.86273765 0.78218716 0.75522049\n",
      " 0.79784206 0.79123487 0.78897007 0.56019389 0.76792144 0.81402702\n",
      " 0.76861664 0.79645015]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(1,60),  \n",
    "    'min_samples_leaf': np.arange(1,50),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.01, 0.0005),\n",
    "    'max_leaf_nodes': np.arange(5, 200), \n",
    "    'max_depth': np.arange(1,50), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = dtree, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, bestRecallTree.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree with GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7680 candidates, totalling 38400 fits\n",
      "The best accuracy score is 0.8552869725125822\n",
      "... with parameters: {'criterion': 'entropy', 'max_depth': 19, 'max_leaf_nodes': 112, 'min_impurity_decrease': 0.005199999999999996, 'min_samples_leaf': 2, 'min_samples_split': 8}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(5,9),  \n",
    "    'min_samples_leaf': np.arange(2,6),\n",
    "    'min_impurity_decrease': np.arange(0.003, 0.007, 0.0001),\n",
    "    'max_leaf_nodes': np.arange(110,114), \n",
    "    'max_depth': np.arange(18,21), \n",
    "    'criterion': ['entropy'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95        43\n",
      "           1       0.94      0.89      0.91        35\n",
      "           2       0.94      0.92      0.93        36\n",
      "           3       0.83      0.83      0.83        41\n",
      "           4       0.90      0.92      0.91        38\n",
      "           5       0.85      0.97      0.91        30\n",
      "           6       0.97      0.97      0.97        37\n",
      "           7       0.94      0.81      0.87        37\n",
      "           8       0.88      0.79      0.84        29\n",
      "           9       0.79      0.88      0.83        34\n",
      "\n",
      "    accuracy                           0.90       360\n",
      "   macro avg       0.90      0.90      0.90       360\n",
      "weighted avg       0.90      0.90      0.90       360\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 2.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, bestRecallTree.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We just looked onto the accuracy and Precision values. The Neural Network model has fetched an accuarcy of 98%.I have considered Decision Tree Classifier and the accuracy is at 90%. By comparing the performnce metrics for both the classifiers, we can clearly see that Neural networks performs the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOig4eSm144+FaPk1GKk187",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "mnist_compete_3_models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b056086e24cb5602cbcb82122035cd3d6ee2ccbf5df29c16e348c108b0f83be3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
