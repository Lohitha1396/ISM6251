{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70a75364",
   "metadata": {},
   "source": [
    "### Setting up the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f6ab257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6440f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "783ea7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"rfm_test_X.csv\")\n",
    "y_test= pd.read_csv(\"rfm_test_y.csv\")\n",
    "X_train= pd.read_csv(\"rfm_train_X.csv\")\n",
    "y_train= pd.read_csv(\"rfm_train_y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51f2622e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recency</th>\n",
       "      <th>monetary</th>\n",
       "      <th>frequency</th>\n",
       "      <th>recency_score</th>\n",
       "      <th>frequency_score</th>\n",
       "      <th>monetary_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>89</td>\n",
       "      <td>1721.57</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59</td>\n",
       "      <td>32</td>\n",
       "      <td>1294.14</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>320</td>\n",
       "      <td>10</td>\n",
       "      <td>153.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>110</td>\n",
       "      <td>781.28</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>96</td>\n",
       "      <td>1841.03</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3155</th>\n",
       "      <td>289</td>\n",
       "      <td>6</td>\n",
       "      <td>94.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3156</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1393.79</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3157</th>\n",
       "      <td>23</td>\n",
       "      <td>119</td>\n",
       "      <td>1228.32</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3158</th>\n",
       "      <td>183</td>\n",
       "      <td>10</td>\n",
       "      <td>213.70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3159</th>\n",
       "      <td>116</td>\n",
       "      <td>87</td>\n",
       "      <td>353.86</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3160 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      recency  monetary  frequency  recency_score  frequency_score  \\\n",
       "0          49        89    1721.57              3                4   \n",
       "1          59        32    1294.14              3                4   \n",
       "2         320        10     153.00              1                1   \n",
       "3          24       110     781.28              4                3   \n",
       "4           8        96    1841.03              5                4   \n",
       "...       ...       ...        ...            ...              ...   \n",
       "3155      289         6      94.00              1                1   \n",
       "3156        1        17    1393.79              5                4   \n",
       "3157       23       119    1228.32              4                4   \n",
       "3158      183        10     213.70              1                1   \n",
       "3159      116        87     353.86              2                2   \n",
       "\n",
       "      monetary_score  \n",
       "0                  4  \n",
       "1                  3  \n",
       "2                  1  \n",
       "3                  4  \n",
       "4                  4  \n",
       "...              ...  \n",
       "3155               1  \n",
       "3156               2  \n",
       "3157               4  \n",
       "3158               1  \n",
       "3159               4  \n",
       "\n",
       "[3160 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47b39d8",
   "metadata": {},
   "source": [
    "\n",
    "### Modelling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90e1c2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe3f329",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee7a1dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "log_reg_model = LogisticRegression()\n",
    "_ = log_reg_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5645fac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.616456</td>\n",
       "      <td>0.590185</td>\n",
       "      <td>0.616456</td>\n",
       "      <td>0.57152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model  Accuracy  Precision    Recall       F1\n",
       "0  default logistic  0.616456   0.590185  0.616456  0.57152"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = log_reg_model.predict(X_test)\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"default logistic\", \n",
    "                                                    'Accuracy': accuracy_score(y_test, model_preds) , \n",
    "                                                    'Precision': precision_score(y_test, model_preds, average='weighted') , \n",
    "                                                    'Recall': recall_score(y_test, model_preds, average='weighted'), \n",
    "                                                    'F1': f1_score(y_test, model_preds, average='weighted') }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99997551",
   "metadata": {},
   "source": [
    "### Logistic Regression Model(RandomizedSearchCV )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbc69e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "20 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'none' (deprecated), 'l2', 'elasticnet'} or None. Got 'elastic' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l1', 'none' (deprecated), 'l2'} or None. Got 'elastic' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l1', 'l2', 'none' (deprecated)} or None. Got 'elastic' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l2', 'none' (deprecated), 'l1'} or None. Got 'elastic' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'none' (deprecated), 'l1', 'l2', 'elasticnet'} or None. Got 'elastic' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'none' (deprecated), 'l2', 'elasticnet', 'l1'} or None. Got 'elastic' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'none' (deprecated), 'l1', 'elasticnet'} or None. Got 'elastic' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'none' (deprecated), 'l1', 'elasticnet', 'l2'} or None. Got 'elastic' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.58987342        nan 0.88892405 0.89018987\n",
      " 0.88829114 0.94683544        nan 0.94651899]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best Precision score is 0.9468354430379746\n",
      "... with parameters: {'warm_start': True, 'solver': 'liblinear', 'penalty': 'l1', 'C': 10}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"Precision\"\n",
    "LR=LogisticRegression()\n",
    "kfolds = 4\n",
    "param_grid = {'C': [0.1, 0.5, 10,0.001], \n",
    "              \"solver\" : [ 'lbfgs', 'liblinear'],\n",
    "              \"penalty\" : ['l1','l2','elastic'],\n",
    "             \"warm_start\":[True, False]} \n",
    "  \n",
    "grid = RandomizedSearchCV(LR, param_grid, verbose = 1, n_jobs = -1)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train, np.ravel(y_train))\n",
    "print(f\"The best {score_measure} score is {grid.best_score_}\")\n",
    "print(f\"... with parameters: {grid.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9ddbea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.616456</td>\n",
       "      <td>0.590185</td>\n",
       "      <td>0.616456</td>\n",
       "      <td>0.571520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Randomised</td>\n",
       "      <td>0.939241</td>\n",
       "      <td>0.946318</td>\n",
       "      <td>0.939241</td>\n",
       "      <td>0.933195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  Accuracy  Precision    Recall        F1\n",
       "0                default logistic  0.616456   0.590185  0.616456  0.571520\n",
       "0  Logistic Regression Randomised  0.939241   0.946318  0.939241  0.933195"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = bestRecallTree.predict(X_test)\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Logistic Regression Randomised\", \n",
    "                                                    'Accuracy': accuracy_score(y_test, model_preds) , \n",
    "                                                    'Precision': precision_score(y_test, model_preds, average='weighted') , \n",
    "                                                    'Recall': recall_score(y_test, model_preds, average='weighted'), \n",
    "                                                    'F1': f1_score(y_test, model_preds, average='weighted') }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5a0d8a",
   "metadata": {},
   "source": [
    "### Logistic Regression Model(GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24a8338b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END .C=1, penalty=l1, solver=liblinear;, score=0.943 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .C=1, penalty=l1, solver=liblinear;, score=0.940 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END .C=1, penalty=l1, solver=liblinear;, score=0.929 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END .C=1, penalty=l1, solver=liblinear;, score=0.935 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END .C=1, penalty=l1, solver=liblinear;, score=0.932 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END .C=5, penalty=l1, solver=liblinear;, score=0.957 total time=   0.4s\n",
      "[CV 2/5] END .C=5, penalty=l1, solver=liblinear;, score=0.946 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END .C=5, penalty=l1, solver=liblinear;, score=0.929 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END .C=5, penalty=l1, solver=liblinear;, score=0.945 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END .C=5, penalty=l1, solver=liblinear;, score=0.948 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5, penalty=l1, solver=liblinear;, score=0.935 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5, penalty=l1, solver=liblinear;, score=0.937 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5, penalty=l1, solver=liblinear;, score=0.915 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5, penalty=l1, solver=liblinear;, score=0.926 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5, penalty=l1, solver=liblinear;, score=0.921 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best precision score is 0.9449367088607594\n",
      "... with parameters: {'C': 5, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"precision\"\n",
    "kfolds = 3\n",
    "param_grid = {'C': [1,5,0.5], \n",
    "              'solver' : [ 'liblinear'],\n",
    "              'penalty' : ['l1']} \n",
    "  \n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, refit = True, verbose = 3)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train, y_train)\n",
    "print(f\"The best {score_measure} score is {grid.best_score_}\")\n",
    "print(f\"... with parameters: {grid.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73b32b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.616456</td>\n",
       "      <td>0.590185</td>\n",
       "      <td>0.616456</td>\n",
       "      <td>0.571520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Randomised</td>\n",
       "      <td>0.939241</td>\n",
       "      <td>0.946318</td>\n",
       "      <td>0.939241</td>\n",
       "      <td>0.933195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Grid</td>\n",
       "      <td>0.930380</td>\n",
       "      <td>0.939948</td>\n",
       "      <td>0.930380</td>\n",
       "      <td>0.918941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  Accuracy  Precision    Recall        F1\n",
       "0                default logistic  0.616456   0.590185  0.616456  0.571520\n",
       "0  Logistic Regression Randomised  0.939241   0.946318  0.939241  0.933195\n",
       "0        Logistic Regression Grid  0.930380   0.939948  0.930380  0.918941"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = bestRecallTree.predict(X_test)\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Logistic Regression Grid\", \n",
    "                                                    'Accuracy': accuracy_score(y_test, model_preds) , \n",
    "                                                    'Precision': precision_score(y_test, model_preds, average='weighted') , \n",
    "                                                    'Recall': recall_score(y_test, model_preds, average='weighted'), \n",
    "                                                    'F1': f1_score(y_test, model_preds, average='weighted') }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "deb1eab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.616456</td>\n",
       "      <td>0.590185</td>\n",
       "      <td>0.616456</td>\n",
       "      <td>0.571520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Grid</td>\n",
       "      <td>0.930380</td>\n",
       "      <td>0.939948</td>\n",
       "      <td>0.930380</td>\n",
       "      <td>0.918941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Randomised</td>\n",
       "      <td>0.939241</td>\n",
       "      <td>0.946318</td>\n",
       "      <td>0.939241</td>\n",
       "      <td>0.933195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  Accuracy  Precision    Recall        F1\n",
       "0                default logistic  0.616456   0.590185  0.616456  0.571520\n",
       "0        Logistic Regression Grid  0.930380   0.939948  0.930380  0.918941\n",
       "0  Logistic Regression Randomised  0.939241   0.946318  0.939241  0.933195"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.sort_values(by =['Recall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e701be5",
   "metadata": {},
   "source": [
    "### Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9ad2823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# instantiate the DecisionTreeClassifier model \n",
    "clf = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)\n",
    "# fit the model\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2931bde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.616456</td>\n",
       "      <td>0.590185</td>\n",
       "      <td>0.616456</td>\n",
       "      <td>0.571520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Randomised</td>\n",
       "      <td>0.939241</td>\n",
       "      <td>0.946318</td>\n",
       "      <td>0.939241</td>\n",
       "      <td>0.933195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Grid</td>\n",
       "      <td>0.930380</td>\n",
       "      <td>0.939948</td>\n",
       "      <td>0.930380</td>\n",
       "      <td>0.918941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision_trees</td>\n",
       "      <td>0.901266</td>\n",
       "      <td>0.838693</td>\n",
       "      <td>0.901266</td>\n",
       "      <td>0.863157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  Accuracy  Precision    Recall        F1\n",
       "0                default logistic  0.616456   0.590185  0.616456  0.571520\n",
       "0  Logistic Regression Randomised  0.939241   0.946318  0.939241  0.933195\n",
       "0        Logistic Regression Grid  0.930380   0.939948  0.930380  0.918941\n",
       "0                  Decision_trees  0.901266   0.838693  0.901266  0.863157"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = clf.predict(X_test)\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Decision_trees\", \n",
    "                                                    'Accuracy': accuracy_score(y_test, model_preds) , \n",
    "                                                    'Precision': precision_score(y_test, model_preds, average='weighted') , \n",
    "                                                    'Recall': recall_score(y_test, model_preds, average='weighted'), \n",
    "                                                    'F1': f1_score(y_test, model_preds, average='weighted') }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446274ee",
   "metadata": {},
   "source": [
    "### Decision tree model (Randomsearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55428b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 500 candidates, totalling 2000 fits\n",
      "The best precision score is nan\n",
      "... with parameters: {'min_samples_split': 36, 'min_samples_leaf': 20, 'min_impurity_decrease': 0.0026, 'max_leaf_nodes': 85, 'max_depth': 41, 'criterion': 'gini'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "12 fits failed out of a total of 2000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 889, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the train scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"precision\"\n",
    "kfolds = 4\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(1,80),  \n",
    "    'min_samples_leaf': np.arange(1,40),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.01, 0.0005),\n",
    "    'max_leaf_nodes': np.arange(5, 200), \n",
    "    'max_depth': np.arange(1,50), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = dtree, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4029273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.616456</td>\n",
       "      <td>0.590185</td>\n",
       "      <td>0.616456</td>\n",
       "      <td>0.571520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Randomised</td>\n",
       "      <td>0.939241</td>\n",
       "      <td>0.946318</td>\n",
       "      <td>0.939241</td>\n",
       "      <td>0.933195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Grid</td>\n",
       "      <td>0.930380</td>\n",
       "      <td>0.939948</td>\n",
       "      <td>0.930380</td>\n",
       "      <td>0.918941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision_trees</td>\n",
       "      <td>0.901266</td>\n",
       "      <td>0.838693</td>\n",
       "      <td>0.901266</td>\n",
       "      <td>0.863157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision_trees_random_Search</td>\n",
       "      <td>0.998734</td>\n",
       "      <td>0.998759</td>\n",
       "      <td>0.998734</td>\n",
       "      <td>0.998733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  Accuracy  Precision    Recall        F1\n",
       "0                default logistic  0.616456   0.590185  0.616456  0.571520\n",
       "0  Logistic Regression Randomised  0.939241   0.946318  0.939241  0.933195\n",
       "0        Logistic Regression Grid  0.930380   0.939948  0.930380  0.918941\n",
       "0                  Decision_trees  0.901266   0.838693  0.901266  0.863157\n",
       "0    Decision_trees_random_Search  0.998734   0.998759  0.998734  0.998733"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = bestRecallTree.predict(X_test)\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Decision_trees_random_Search\", \n",
    "                                                    'Accuracy': accuracy_score(y_test, model_preds) , \n",
    "                                                    'Precision': precision_score(y_test, model_preds, average='weighted') , \n",
    "                                                    'Recall': recall_score(y_test, model_preds, average='weighted'), \n",
    "                                                    'F1': f1_score(y_test, model_preds, average='weighted') }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321fc5f7",
   "metadata": {},
   "source": [
    "### Decision tree model (Gridsearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9380c4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10000 candidates, totalling 50000 fits\n",
      "The best precision score is nan\n",
      "... with parameters: {'criterion': 'gini', 'max_depth': 32, 'max_leaf_nodes': 70, 'min_impurity_decrease': 0.004, 'min_samples_leaf': 27, 'min_samples_split': 45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the train scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"precision\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(45,55),  \n",
    "    'min_samples_leaf': np.arange(27,32),\n",
    "    'min_impurity_decrease': np.arange(0.004, 0.005, 0.0001),\n",
    "    'max_leaf_nodes': np.arange(70,75), \n",
    "    'max_depth': np.arange(32,36), \n",
    "    'criterion': ['gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d5891d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.616456</td>\n",
       "      <td>0.590185</td>\n",
       "      <td>0.616456</td>\n",
       "      <td>0.571520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Randomised</td>\n",
       "      <td>0.939241</td>\n",
       "      <td>0.946318</td>\n",
       "      <td>0.939241</td>\n",
       "      <td>0.933195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Grid</td>\n",
       "      <td>0.930380</td>\n",
       "      <td>0.939948</td>\n",
       "      <td>0.930380</td>\n",
       "      <td>0.918941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision_trees</td>\n",
       "      <td>0.901266</td>\n",
       "      <td>0.838693</td>\n",
       "      <td>0.901266</td>\n",
       "      <td>0.863157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision_trees_random_Search</td>\n",
       "      <td>0.998734</td>\n",
       "      <td>0.998759</td>\n",
       "      <td>0.998734</td>\n",
       "      <td>0.998733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision_trees_Grid_Search</td>\n",
       "      <td>0.997468</td>\n",
       "      <td>0.997504</td>\n",
       "      <td>0.997468</td>\n",
       "      <td>0.997466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  Accuracy  Precision    Recall        F1\n",
       "0                default logistic  0.616456   0.590185  0.616456  0.571520\n",
       "0  Logistic Regression Randomised  0.939241   0.946318  0.939241  0.933195\n",
       "0        Logistic Regression Grid  0.930380   0.939948  0.930380  0.918941\n",
       "0                  Decision_trees  0.901266   0.838693  0.901266  0.863157\n",
       "0    Decision_trees_random_Search  0.998734   0.998759  0.998734  0.998733\n",
       "0      Decision_trees_Grid_Search  0.997468   0.997504  0.997468  0.997466"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = bestRecallTree.predict(X_test)\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Decision_trees_Grid_Search\", \n",
    "                                                    'Accuracy': accuracy_score(y_test, model_preds) , \n",
    "                                                    'Precision': precision_score(y_test, model_preds, average='weighted') , \n",
    "                                                    'Recall': recall_score(y_test, model_preds, average='weighted'), \n",
    "                                                    'F1': f1_score(y_test, model_preds, average='weighted') }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08eb91b9",
   "metadata": {},
   "source": [
    "# SVM Classification model(Linear Kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab7b2c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_lin_model = SVC(kernel=\"linear\", probability=True)\n",
    "_ = svm_lin_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1de074a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.616456</td>\n",
       "      <td>0.590185</td>\n",
       "      <td>0.616456</td>\n",
       "      <td>0.571520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Randomised</td>\n",
       "      <td>0.939241</td>\n",
       "      <td>0.946318</td>\n",
       "      <td>0.939241</td>\n",
       "      <td>0.933195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Grid</td>\n",
       "      <td>0.930380</td>\n",
       "      <td>0.939948</td>\n",
       "      <td>0.930380</td>\n",
       "      <td>0.918941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision_trees</td>\n",
       "      <td>0.901266</td>\n",
       "      <td>0.838693</td>\n",
       "      <td>0.901266</td>\n",
       "      <td>0.863157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision_trees_random_Search</td>\n",
       "      <td>0.998734</td>\n",
       "      <td>0.998759</td>\n",
       "      <td>0.998734</td>\n",
       "      <td>0.998733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision_trees_Grid_Search</td>\n",
       "      <td>0.997468</td>\n",
       "      <td>0.997504</td>\n",
       "      <td>0.997468</td>\n",
       "      <td>0.997466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm_linear</td>\n",
       "      <td>0.998734</td>\n",
       "      <td>0.998743</td>\n",
       "      <td>0.998734</td>\n",
       "      <td>0.998733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  Accuracy  Precision    Recall        F1\n",
       "0                default logistic  0.616456   0.590185  0.616456  0.571520\n",
       "0  Logistic Regression Randomised  0.939241   0.946318  0.939241  0.933195\n",
       "0        Logistic Regression Grid  0.930380   0.939948  0.930380  0.918941\n",
       "0                  Decision_trees  0.901266   0.838693  0.901266  0.863157\n",
       "0    Decision_trees_random_Search  0.998734   0.998759  0.998734  0.998733\n",
       "0      Decision_trees_Grid_Search  0.997468   0.997504  0.997468  0.997466\n",
       "0                      svm_linear  0.998734   0.998743  0.998734  0.998733"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = svm_lin_model.predict(X_test)\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"svm_linear\", \n",
    "                                                    'Accuracy': accuracy_score(y_test, model_preds) , \n",
    "                                                    'Precision': precision_score(y_test, model_preds, average='weighted') , \n",
    "                                                    'Recall': recall_score(y_test, model_preds, average='weighted'), \n",
    "                                                    'F1': f1_score(y_test, model_preds, average='weighted') }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7127fcf",
   "metadata": {},
   "source": [
    "# SVM Classification model(RBF Kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc6dc164",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf_model = SVC(kernel=\"rbf\", C=10, gamma='scale', probability=True)\n",
    "_ = svm_rbf_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb6390be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.616456</td>\n",
       "      <td>0.590185</td>\n",
       "      <td>0.616456</td>\n",
       "      <td>0.571520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Randomised</td>\n",
       "      <td>0.939241</td>\n",
       "      <td>0.946318</td>\n",
       "      <td>0.939241</td>\n",
       "      <td>0.933195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Grid</td>\n",
       "      <td>0.930380</td>\n",
       "      <td>0.939948</td>\n",
       "      <td>0.930380</td>\n",
       "      <td>0.918941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision_trees</td>\n",
       "      <td>0.901266</td>\n",
       "      <td>0.838693</td>\n",
       "      <td>0.901266</td>\n",
       "      <td>0.863157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision_trees_random_Search</td>\n",
       "      <td>0.998734</td>\n",
       "      <td>0.998759</td>\n",
       "      <td>0.998734</td>\n",
       "      <td>0.998733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision_trees_Grid_Search</td>\n",
       "      <td>0.997468</td>\n",
       "      <td>0.997504</td>\n",
       "      <td>0.997468</td>\n",
       "      <td>0.997466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm_linear</td>\n",
       "      <td>0.998734</td>\n",
       "      <td>0.998743</td>\n",
       "      <td>0.998734</td>\n",
       "      <td>0.998733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm_rbf</td>\n",
       "      <td>0.631646</td>\n",
       "      <td>0.583086</td>\n",
       "      <td>0.631646</td>\n",
       "      <td>0.591722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  Accuracy  Precision    Recall        F1\n",
       "0                default logistic  0.616456   0.590185  0.616456  0.571520\n",
       "0  Logistic Regression Randomised  0.939241   0.946318  0.939241  0.933195\n",
       "0        Logistic Regression Grid  0.930380   0.939948  0.930380  0.918941\n",
       "0                  Decision_trees  0.901266   0.838693  0.901266  0.863157\n",
       "0    Decision_trees_random_Search  0.998734   0.998759  0.998734  0.998733\n",
       "0      Decision_trees_Grid_Search  0.997468   0.997504  0.997468  0.997466\n",
       "0                      svm_linear  0.998734   0.998743  0.998734  0.998733\n",
       "0                         svm_rbf  0.631646   0.583086  0.631646  0.591722"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = svm_rbf_model.predict(X_test)\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"svm_rbf\", \n",
    "                                                    'Accuracy': accuracy_score(y_test, model_preds) , \n",
    "                                                    'Precision': precision_score(y_test, model_preds, average='weighted') , \n",
    "                                                    'Recall': recall_score(y_test, model_preds, average='weighted'), \n",
    "                                                    'F1': f1_score(y_test, model_preds, average='weighted') }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c391a97",
   "metadata": {},
   "source": [
    "# SVM Classification model(Polynomial Kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c33e8d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_poly_model = SVC(kernel=\"poly\", degree=3, coef0=1, C=10, probability=True)\n",
    "_ = svm_poly_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "258c6fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.616456</td>\n",
       "      <td>0.590185</td>\n",
       "      <td>0.616456</td>\n",
       "      <td>0.571520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Randomised</td>\n",
       "      <td>0.939241</td>\n",
       "      <td>0.946318</td>\n",
       "      <td>0.939241</td>\n",
       "      <td>0.933195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Grid</td>\n",
       "      <td>0.930380</td>\n",
       "      <td>0.939948</td>\n",
       "      <td>0.930380</td>\n",
       "      <td>0.918941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision_trees</td>\n",
       "      <td>0.901266</td>\n",
       "      <td>0.838693</td>\n",
       "      <td>0.901266</td>\n",
       "      <td>0.863157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision_trees_random_Search</td>\n",
       "      <td>0.998734</td>\n",
       "      <td>0.998759</td>\n",
       "      <td>0.998734</td>\n",
       "      <td>0.998733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision_trees_Grid_Search</td>\n",
       "      <td>0.997468</td>\n",
       "      <td>0.997504</td>\n",
       "      <td>0.997468</td>\n",
       "      <td>0.997466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm_linear</td>\n",
       "      <td>0.998734</td>\n",
       "      <td>0.998743</td>\n",
       "      <td>0.998734</td>\n",
       "      <td>0.998733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm_rbf</td>\n",
       "      <td>0.631646</td>\n",
       "      <td>0.583086</td>\n",
       "      <td>0.631646</td>\n",
       "      <td>0.591722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm_poly</td>\n",
       "      <td>0.673418</td>\n",
       "      <td>0.654952</td>\n",
       "      <td>0.673418</td>\n",
       "      <td>0.639693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  Accuracy  Precision    Recall        F1\n",
       "0                default logistic  0.616456   0.590185  0.616456  0.571520\n",
       "0  Logistic Regression Randomised  0.939241   0.946318  0.939241  0.933195\n",
       "0        Logistic Regression Grid  0.930380   0.939948  0.930380  0.918941\n",
       "0                  Decision_trees  0.901266   0.838693  0.901266  0.863157\n",
       "0    Decision_trees_random_Search  0.998734   0.998759  0.998734  0.998733\n",
       "0      Decision_trees_Grid_Search  0.997468   0.997504  0.997468  0.997466\n",
       "0                      svm_linear  0.998734   0.998743  0.998734  0.998733\n",
       "0                         svm_rbf  0.631646   0.583086  0.631646  0.591722\n",
       "0                        svm_poly  0.673418   0.654952  0.673418  0.639693"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = svm_poly_model.predict(X_test)\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"svm_poly\", \n",
    "                                                    'Accuracy': accuracy_score(y_test, model_preds) , \n",
    "                                                    'Precision': precision_score(y_test, model_preds, average='weighted') , \n",
    "                                                    'Recall': recall_score(y_test, model_preds, average='weighted'), \n",
    "                                                    'F1': f1_score(y_test, model_preds, average='weighted') }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f65424",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8b5aad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59883108",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.47 s\n",
      "Wall time: 1.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ann = MLPClassifier(hidden_layer_sizes=(60,50,40),solver='adam', max_iter=200)\n",
    "_ = ann.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e8e0e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 78.1 ms\n",
      "Wall time: 2.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = ann.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa8d1793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.45      0.55        51\n",
      "           1       0.68      0.77      0.72        99\n",
      "           2       0.67      0.50      0.57        16\n",
      "           3       0.93      0.11      0.19       120\n",
      "           4       0.87      0.95      0.91       186\n",
      "           5       0.49      0.77      0.60       141\n",
      "           6       0.42      0.76      0.54        42\n",
      "           7       1.00      0.45      0.62        11\n",
      "           8       0.72      0.80      0.76        99\n",
      "           9       0.88      0.28      0.42        25\n",
      "\n",
      "    accuracy                           0.67       790\n",
      "   macro avg       0.74      0.58      0.59       790\n",
      "weighted avg       0.73      0.67      0.63       790\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b12a8c5",
   "metadata": {},
   "source": [
    "## Neural Network with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "313766f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "34 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "34 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 749, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "  File \"C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 491, in _fit\n",
      "    raise ValueError(\n",
      "ValueError: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the train scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\extmath.py:189: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'sgd', 'max_iter': 5000, 'learning_rate_init': 0.1, 'learning_rate': 'invscaling', 'hidden_layer_sizes': (70, 50, 40), 'alpha': 0.2, 'activation': 'relu'}\n",
      "CPU times: total: 5min 8s\n",
      "Wall time: 16min 49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"precision\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (50,), (70,),(50,30), (40,20), (60,40, 20), (70,50,40)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0, .2, .5, .7, 1],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1, 0.2, 0.5],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = RandomizedSearchCV(estimator = ann, param_distributions=param_grid, cv=kfolds, n_iter=100,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "948de971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        51\n",
      "           1       0.00      0.00      0.00        99\n",
      "           2       0.00      0.00      0.00        16\n",
      "           3       0.00      0.00      0.00       120\n",
      "           4       0.24      1.00      0.38       186\n",
      "           5       0.00      0.00      0.00       141\n",
      "           6       0.00      0.00      0.00        42\n",
      "           7       0.00      0.00      0.00        11\n",
      "           8       0.00      0.00      0.00        99\n",
      "           9       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.24       790\n",
      "   macro avg       0.02      0.10      0.04       790\n",
      "weighted avg       0.06      0.24      0.09       790\n",
      "\n",
      "CPU times: total: 93.8 ms\n",
      "Wall time: 17 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\extmath.py:189: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f50ee1",
   "metadata": {},
   "source": [
    "## Neural Network Model With GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41283ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the train scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jeshwant\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'alpha': 0.3, 'hidden_layer_sizes': (40, 20), 'learning_rate': 'adaptive', 'learning_rate_init': 0.005, 'max_iter': 5000, 'solver': 'adam'}\n",
      "CPU times: total: 3.88 s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"precision\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (40,20), (50,30), (50,40,30), (80,)],\n",
    "    'activation': ['relu','tanh'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [.3, .5, 1],\n",
    "    'learning_rate': ['adaptive', 'invscaling'],\n",
    "    'learning_rate_init': [0.005, 0.01, 0.15],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = GridSearchCV(estimator = ann, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a14ac67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.67      0.72        51\n",
      "           1       0.87      0.78      0.82        99\n",
      "           2       0.27      0.81      0.41        16\n",
      "           3       0.59      1.00      0.74       120\n",
      "           4       0.89      0.96      0.92       186\n",
      "           5       1.00      0.03      0.06       141\n",
      "           6       0.52      0.76      0.62        42\n",
      "           7       0.25      0.09      0.13        11\n",
      "           8       0.70      0.90      0.78        99\n",
      "           9       1.00      0.20      0.33        25\n",
      "\n",
      "    accuracy                           0.70       790\n",
      "   macro avg       0.68      0.62      0.55       790\n",
      "weighted avg       0.79      0.70      0.64       790\n",
      "\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 17 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b06789",
   "metadata": {},
   "source": [
    "## Using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b040b8",
   "metadata": {},
   "source": [
    "### Deep Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5b164e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "84e050c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f21d4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "segment_encoded\n",
       "4                  754\n",
       "5                  559\n",
       "3                  460\n",
       "1                  447\n",
       "8                  367\n",
       "0                  252\n",
       "6                  135\n",
       "2                   75\n",
       "9                   70\n",
       "7                   41\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c874696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(790, 6)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4dc92625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "segment_encoded\n",
       "4                  186\n",
       "5                  141\n",
       "3                  120\n",
       "1                   99\n",
       "8                   99\n",
       "0                   51\n",
       "6                   42\n",
       "9                   25\n",
       "2                   16\n",
       "7                   11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cea5e409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 141 ms\n",
      "Wall time: 186 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# create model stucture\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Input(6))\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax')) # final layer, 10 categories\n",
    "\n",
    "\n",
    "# compile\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# if you want to overide the defaults for the optimizer....\n",
    "#adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "#model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eb03a800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1252 - accuracy: 0.9646 - val_loss: 0.4234 - val_accuracy: 0.9076\n",
      "Epoch 2/22\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 1.1377 - accuracy: 0.8057 - val_loss: 0.3499 - val_accuracy: 0.8949\n",
      "Epoch 3/22\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2954 - accuracy: 0.9184 - val_loss: 0.2205 - val_accuracy: 0.8975\n",
      "Epoch 4/22\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2357 - accuracy: 0.9339 - val_loss: 0.2748 - val_accuracy: 0.9089\n",
      "Epoch 5/22\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8864 - val_loss: 0.5026 - val_accuracy: 0.8481\n",
      "Epoch 6/22\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2134 - accuracy: 0.9272 - val_loss: 0.3519 - val_accuracy: 0.8747\n",
      "Epoch 7/22\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1569 - accuracy: 0.9557 - val_loss: 0.1597 - val_accuracy: 0.9380\n",
      "Epoch 8/22\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2657 - accuracy: 0.9228 - val_loss: 0.2769 - val_accuracy: 0.9329\n",
      "Epoch 9/22\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2202 - accuracy: 0.9297 - val_loss: 0.1463 - val_accuracy: 0.9494\n",
      "Epoch 10/22\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1293 - accuracy: 0.9623 - val_loss: 0.1920 - val_accuracy: 0.9316\n",
      "Epoch 11/22\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1330 - accuracy: 0.9595 - val_loss: 0.2265 - val_accuracy: 0.9291\n",
      "Epoch 12/22\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2071 - accuracy: 0.9288 - val_loss: 0.1370 - val_accuracy: 0.9582\n",
      "Epoch 13/22\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1136 - accuracy: 0.9639 - val_loss: 0.1309 - val_accuracy: 0.9620\n",
      "Epoch 14/22\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1121 - accuracy: 0.9677 - val_loss: 0.1407 - val_accuracy: 0.9481\n",
      "Epoch 15/22\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1637 - accuracy: 0.9421 - val_loss: 0.1162 - val_accuracy: 0.9646\n",
      "Epoch 16/22\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1200 - accuracy: 0.9604 - val_loss: 0.1332 - val_accuracy: 0.9481\n",
      "Epoch 17/22\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2884 - accuracy: 0.9241 - val_loss: 0.2401 - val_accuracy: 0.9025\n",
      "Epoch 18/22\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1602 - accuracy: 0.9456 - val_loss: 0.2193 - val_accuracy: 0.9063\n",
      "Epoch 19/22\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3360 - accuracy: 0.9060 - val_loss: 0.1444 - val_accuracy: 0.9456\n",
      "Epoch 20/22\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1318 - accuracy: 0.9627 - val_loss: 0.3550 - val_accuracy: 0.9177\n",
      "Epoch 21/22\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2632 - accuracy: 0.9244 - val_loss: 0.5474 - val_accuracy: 0.9038\n",
      "Epoch 22/22\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2823 - accuracy: 0.9104 - val_loss: 0.4755 - val_accuracy: 0.8101\n",
      "CPU times: total: 14.2 s\n",
      "Wall time: 2.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=22, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a56f9d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.47551319003105164, 0.8101266026496887]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "scores\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "516ee50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.48\n",
      "accuracy: 81.01%\n"
     ]
    }
   ],
   "source": [
    "# let's format this into a better output...\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8f8222",
   "metadata": {},
   "source": [
    "## Wide and Deep Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4959d833",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model: for multi-class\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Input(shape=6))\n",
    "model.add(keras.layers.Dense(60, activation='relu'))\n",
    "model.add(keras.layers.Dense(60, activation='relu'))\n",
    "model.add(keras.layers.Dense(60, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f9789fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "#Optimizer:\n",
    "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b0d29d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9650 - accuracy: 0.6820 - val_loss: 0.5845 - val_accuracy: 0.7658\n",
      "Epoch 2/40\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.8057 - val_loss: 0.3428 - val_accuracy: 0.8722\n",
      "Epoch 3/40\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2449 - accuracy: 0.9165 - val_loss: 0.2432 - val_accuracy: 0.9291\n",
      "Epoch 4/40\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2086 - accuracy: 0.9370 - val_loss: 0.1890 - val_accuracy: 0.9481\n",
      "Epoch 5/40\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1590 - accuracy: 0.9532 - val_loss: 0.1468 - val_accuracy: 0.9570\n",
      "Epoch 6/40\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1868 - accuracy: 0.9405 - val_loss: 0.2059 - val_accuracy: 0.9152\n",
      "Epoch 7/40\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.8975 - val_loss: 1.2666 - val_accuracy: 0.6747\n",
      "Epoch 8/40\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.7224 - accuracy: 0.7060 - val_loss: 0.6352 - val_accuracy: 0.7139\n",
      "Epoch 9/40\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7769 - val_loss: 0.3726 - val_accuracy: 0.8392\n",
      "Epoch 10/40\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3130 - accuracy: 0.8570 - val_loss: 0.2694 - val_accuracy: 0.9063\n",
      "Epoch 11/40\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2288 - accuracy: 0.9291 - val_loss: 0.2595 - val_accuracy: 0.9038\n",
      "Epoch 12/40\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2080 - accuracy: 0.9323 - val_loss: 0.2421 - val_accuracy: 0.9190\n",
      "Epoch 13/40\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2135 - accuracy: 0.9203 - val_loss: 0.1904 - val_accuracy: 0.9342\n",
      "Epoch 14/40\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1720 - accuracy: 0.9386 - val_loss: 0.1651 - val_accuracy: 0.9506\n",
      "Epoch 15/40\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2024 - accuracy: 0.9285 - val_loss: 0.1612 - val_accuracy: 0.9367\n",
      "Epoch 16/40\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1960 - accuracy: 0.9241 - val_loss: 0.2870 - val_accuracy: 0.9063\n",
      "Epoch 17/40\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2324 - accuracy: 0.9120 - val_loss: 0.2015 - val_accuracy: 0.9215\n",
      "Epoch 18/40\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1632 - accuracy: 0.9377 - val_loss: 0.1476 - val_accuracy: 0.9494\n",
      "Epoch 19/40\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.7716 - accuracy: 0.7348 - val_loss: 0.5842 - val_accuracy: 0.7532\n",
      "Epoch 20/40\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.8098 - val_loss: 0.3382 - val_accuracy: 0.8354\n",
      "Epoch 21/40\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3088 - accuracy: 0.8389 - val_loss: 0.2783 - val_accuracy: 0.8595\n",
      "Epoch 22/40\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2570 - accuracy: 0.8769 - val_loss: 0.3041 - val_accuracy: 0.8620\n",
      "Epoch 23/40\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2347 - accuracy: 0.9095 - val_loss: 0.2159 - val_accuracy: 0.9278\n",
      "Epoch 24/40\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1972 - accuracy: 0.9323 - val_loss: 0.1887 - val_accuracy: 0.9418\n",
      "Epoch 25/40\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1620 - accuracy: 0.9503 - val_loss: 0.1584 - val_accuracy: 0.9506\n",
      "Epoch 26/40\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1369 - accuracy: 0.9566 - val_loss: 0.1154 - val_accuracy: 0.9759\n",
      "Epoch 27/40\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1222 - accuracy: 0.9630 - val_loss: 0.1410 - val_accuracy: 0.9620\n",
      "Epoch 28/40\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1334 - accuracy: 0.9576 - val_loss: 0.2448 - val_accuracy: 0.9316\n",
      "Epoch 29/40\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.8657 - accuracy: 0.7592 - val_loss: 1.0626 - val_accuracy: 0.6329\n",
      "Epoch 30/40\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.0101 - accuracy: 0.6883 - val_loss: 0.5880 - val_accuracy: 0.6949\n",
      "Epoch 31/40\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.7813 - val_loss: 0.3588 - val_accuracy: 0.8684\n",
      "Epoch 32/40\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3251 - accuracy: 0.8497 - val_loss: 0.2957 - val_accuracy: 0.8873\n",
      "Epoch 33/40\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2547 - accuracy: 0.8984 - val_loss: 0.2457 - val_accuracy: 0.9190\n",
      "Epoch 34/40\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2251 - accuracy: 0.9231 - val_loss: 0.2622 - val_accuracy: 0.8797\n",
      "Epoch 35/40\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2302 - accuracy: 0.9155 - val_loss: 0.2618 - val_accuracy: 0.9000\n",
      "Epoch 36/40\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3060 - accuracy: 0.9139 - val_loss: 0.9309 - val_accuracy: 0.7456\n",
      "Epoch 37/40\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.3326 - accuracy: 0.8766 - val_loss: 0.2471 - val_accuracy: 0.9253\n",
      "Epoch 38/40\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1702 - accuracy: 0.9494 - val_loss: 0.1671 - val_accuracy: 0.9557\n",
      "Epoch 39/40\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5286 - accuracy: 0.7968 - val_loss: 0.3132 - val_accuracy: 0.8696\n",
      "Epoch 40/40\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2765 - accuracy: 0.8940 - val_loss: 0.2158 - val_accuracy: 0.9418\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=40, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c6c51812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.21578212082386017, 0.9417721629142761]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8ce5bb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.22\n",
      "accuracy: 94.18%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5e300828",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Wide and Deep network with RandomGridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6f0f857a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# If you don't have the following installed, from command line '!pip install scikeras'\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.initializers import GlorotNormal\n",
    "\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "def build_clf(hidden_layer_sizes, dropout):\n",
    "    ann = tf.keras.models.Sequential()\n",
    "    ann.add(keras.layers.Input(shape=6)),\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        model.add(keras.layers.Dense(hidden_layer_size, kernel_initializer= tf.keras.initializers.GlorotNormal(), \n",
    "                                     bias_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None), activation=\"relu\"))\n",
    "        model.add(keras.layers.Dropout(dropout))\n",
    "    ann.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "    ann.compile(loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return ann\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "24ce0906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "keras_clf = KerasClassifier(\n",
    "    model=build_clf,\n",
    "    hidden_layer_sizes=64,\n",
    "    dropout = 0.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5821bf47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model', 'build_fn', 'warm_start', 'random_state', 'optimizer', 'loss', 'metrics', 'batch_size', 'validation_batch_size', 'verbose', 'callbacks', 'validation_split', 'shuffle', 'run_eagerly', 'epochs', 'hidden_layer_sizes', 'dropout', 'class_weight'])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params = {\n",
    "    'optimizer__learning_rate': [0.0005, 0.001, 0.005],\n",
    "    'model__hidden_layer_sizes': [(70,),(90, ), (100,), (100, 90)],\n",
    "    'model__dropout': [0, 0.1],\n",
    "    'batch_size':[20, 60, 100],\n",
    "    'epochs':[10, 50, 100],\n",
    "    'optimizer':[\"adam\",'sgd']\n",
    "}\n",
    "keras_clf.get_params().keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0f15cc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 997us/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 965us/step\n",
      "32/32 [==============================] - 0s 997us/step\n",
      "32/32 [==============================] - 0s 965us/step\n",
      "32/32 [==============================] - 0s 901us/step\n",
      "32/32 [==============================] - 0s 933us/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 901us/step\n",
      "32/32 [==============================] - 0s 901us/step\n",
      "32/32 [==============================] - 0s 933us/step\n",
      "32/32 [==============================] - 0s 933us/step\n",
      "32/32 [==============================] - 0s 901us/step\n",
      "32/32 [==============================] - 0s 901us/step\n",
      "32/32 [==============================] - 0s 901us/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 933us/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 997us/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 997us/step\n",
      "32/32 [==============================] - 0s 933us/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 869us/step\n",
      "32/32 [==============================] - 0s 933us/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 897us/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 898us/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 997us/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 898us/step\n",
      "11/11 [==============================] - 0s 898us/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 997us/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 997us/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 898us/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 997us/step\n",
      "7/7 [==============================] - 0s 997us/step\n",
      "7/7 [==============================] - 0s 997us/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 933us/step\n",
      "32/32 [==============================] - 0s 933us/step\n",
      "32/32 [==============================] - 0s 965us/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 933us/step\n",
      "32/32 [==============================] - 0s 997us/step\n",
      "32/32 [==============================] - 0s 901us/step\n",
      "32/32 [==============================] - 0s 933us/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 933us/step\n",
      "32/32 [==============================] - 0s 933us/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 836us/step\n",
      "32/32 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 898us/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 997us/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 901us/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 901us/step\n",
      "32/32 [==============================] - 0s 901us/step\n",
      "32/32 [==============================] - 0s 965us/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 898us/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 898us/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 898us/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 898us/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 898us/step\n",
      "11/11 [==============================] - 0s 898us/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 997us/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 898us/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 996us/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "7/7 [==============================] - 0s 997us/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 997us/step\n",
      "7/7 [==============================] - 0s 997us/step\n",
      "7/7 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 869us/step\n",
      "32/32 [==============================] - 0s 901us/step\n",
      "32/32 [==============================] - 0s 933us/step\n",
      "32/32 [==============================] - 0s 933us/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 933us/step\n",
      "32/32 [==============================] - 0s 933us/step\n",
      "32/32 [==============================] - 0s 933us/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 997us/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 997us/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 997us/step\n",
      "32/32 [==============================] - 0s 901us/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 997us/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 997us/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "11/11 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "rnd_search_cv = RandomizedSearchCV(estimator=keras_clf, param_distributions=params, scoring='accuracy', n_iter=50, cv=5)\n",
    "\n",
    "import sys\n",
    "sys.setrecursionlimit(10000) # note: the default is 3000 (python 3.9)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "callback = [earlystop]\n",
    "\n",
    "_ = rnd_search_cv.fit(X_train, y_train, callbacks=callback, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ec62b625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer__learning_rate': 0.005,\n",
       " 'optimizer': 'sgd',\n",
       " 'model__hidden_layer_sizes': (70,),\n",
       " 'model__dropout': 0,\n",
       " 'epochs': 100,\n",
       " 'batch_size': 20}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7e08bd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimizer__learning_rate': 0.005, 'optimizer': 'sgd', 'model__hidden_layer_sizes': (70,), 'model__dropout': 0, 'epochs': 100, 'batch_size': 20}\n"
     ]
    }
   ],
   "source": [
    "best_net = rnd_search_cv.best_estimator_\n",
    "print(rnd_search_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "67c24976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.94      0.83        51\n",
      "           1       0.79      0.98      0.87        99\n",
      "           2       1.00      0.31      0.48        16\n",
      "           3       0.97      0.96      0.96       120\n",
      "           4       0.99      0.96      0.98       186\n",
      "           5       0.91      0.88      0.89       141\n",
      "           6       0.83      0.81      0.82        42\n",
      "           7       1.00      1.00      1.00        11\n",
      "           8       0.85      0.86      0.85        99\n",
      "           9       1.00      0.36      0.53        25\n",
      "\n",
      "    accuracy                           0.89       790\n",
      "   macro avg       0.91      0.81      0.82       790\n",
      "weighted avg       0.90      0.89      0.89       790\n",
      "\n",
      "CPU times: total: 891 ms\n",
      "Wall time: 225 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = best_net.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afc3a78",
   "metadata": {},
   "source": [
    "# Here we have considered the Neural Network, Neutral network with Random search, Neutral network with grid search, Using Keras Deep Network, Wide and Deep Network, Wide and Deep network with Randomgridsearch. \n",
    "\n",
    "# The Accuracy is the highest for  Decision Trees Random Search classifier\twith 99.8734%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b171c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c0fe1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
